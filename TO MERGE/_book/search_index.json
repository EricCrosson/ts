[
["under-development.html", "Chapter 5 Under development ", " Chapter 5 Under development "],
["autoregressive-moving-average-models.html", "5.1 Autoregressive Moving Average Models ⚠️", " 5.1 Autoregressive Moving Average Models ⚠️ ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric Definition 4.1 (ARMA models) A process \\((X_{t})\\) is an ARMA(\\(p\\),\\(q\\)) process if \\((X_t)\\) (or \\((X_{t}-\\mathbb{E}[X_{t}])\\)) satisfies the linear difference equation \\[X_{t} = \\phi_{1}X_{t-1} + \\cdots + \\phi_{p}X_{t-p} + W_{t}+\\theta_{1}W_{t-1}+ \\cdots+\\theta_{q}W_{t-q},\\] where \\(W_{t}\\sim \\mathcal{N}(0,\\sigma_{w}^2)\\). An ARMA(\\(p\\),\\(q\\)) can be written in concise form as: $( B ) \\[X_t = \\theta \\left( B \\right)W_t, \\] where \\(\\phi(z)\\) and \\(\\theta(z)\\) are AR and MA polynomials: \\[\\phi(z)=1-\\phi_{1}z-\\cdots-\\phi_{p}z^p \\] \\[\\theta(z)=1+\\theta_{1}z+\\cdots+\\theta_{q}z^q. \\] With this in mind, several remarks can be made: Assume \\(\\mathbb{E}(X_{t})=\\mu = 0\\). Otherwise you must substitute \\(X_{t} - \\mu\\) for \\(X_{t}\\). If \\(p=0\\), then ARMA\\((p=0,q)=\\) MA\\((q)\\) process. If \\(q=0\\), then ARMA\\((p,q=0)=\\) AR\\((p)\\) process. We mainly work with ARMA models that are causal and invertible. An ARMA model is causal and invertible if its AR part is causal and its MA part is invertible. AR\\((p)\\) models are always invertible and MA\\((q)\\) models are always causal. Forecasting with ARMA process relies on the same techniques used with MA process. ARMA models can have redundante parameters. This is illustrated in the following examples: Example 4.1 (Parameter Redundancy of ARMA models) Let us consider the process: \\[\\begin{align*} X_t &amp;= W_t \\\\ X_t - 0.9 X_{t-1} &amp;= W_t - 0.9 W_{t-1}\\\\ X_t &amp;= 0.9 X_{t-1} + W_t - 0.9 W_{t-1}. \\end{align*}\\] Therefore, \\(X_t = W_t\\) can be written as \\(X_t = 0.9 X_{t-1} + W_t - 0.9 W_{t-1}\\), which looks a lot like an ARMA(1,1). To assess the parameter redundancy of this ARMA models, it is useful to express the models in operator form, in this case: \\[\\begin{equation*} X_t = 0.9 X_{t-1} + W_t - 0.9 W_t \\Longleftrightarrow (1 - 0.9B) X_t = (1 - 0.9 B) W_t. \\end{equation*}\\] It clearly appears that \\((1 - 0.9B)\\) can be simplified in the above equation yielding to our original model \\(X_t = W_t\\). In general, if a model has autoregressive and moving average operators that share a common root then the model has redundant parameters. Example 4.2 (Parameter Redundancy of ARMA models) Consider the following example: \\[\\begin{equation*} X_t = 0.3 X_{t-1} + 0.1 X_{t-2} + W_t + W_{t-1} + 0.16 W_{t-2}, \\end{equation*}\\] which is an ARMA(2,2). By rearranging the terms, we obtain \\[\\begin{equation*} \\begin{aligned} X_t &amp;= 0.3 X_{t-1} + 0.1 X_{t-2} + W_t + W_{t-1} + 0.16 W_{t-2}\\\\ X_t - 0.3 X_{t-1} - 0.1 X_{t-2} &amp;= W_t + W_{t-1} + 0.16 W_{t-2}\\\\ (1 - 0.3 B - 0.1 B^2 ) X_t &amp;= (1 + B + 0.16B^2) W_t\\\\ (1 + 0.2B)(1 - 0.5 B) X_t &amp;= (1 + 0.2B)(1 + 0.8 B) W_t\\\\ (1 - 0.5 B) X_t &amp;= (1 + 0.8 B) W_t\\\\ X_t &amp;= 0.5 X_{t-1} + W_t - 0.8 W_{t-1}. \\end{aligned} \\end{equation*}\\] Therefore, our initial model is in fact an ARMA(1,1). Note that this model is causal (as \\(|\\phi|&lt;1\\)) and invertible (as \\(|\\theta| &lt; 1\\)). 5.1.1 ACF/PACF Derivation the ACF/PACF of ARMA(\\(p\\),\\(q\\)) is generally difficult. : Given an ARMA(1,1), we have \\(\\rho(h) = \\phi^{h-1} \\rho(1)\\) where \\[\\begin{equation*} \\rho(1) = \\frac{\\left(1+\\theta \\phi \\right)\\left(\\theta + \\phi\\right)}{1+2\\phi\\theta+\\theta^2}. \\end{equation*}\\] It is difficult to identify ARMA process from their ACF/PACF. Indeed, we have: (#acfpacf) Caption here AR(\\(p\\)) MA(\\(q\\)) ARMA(\\(p\\),\\(q\\)) ACF Tails off Cuts off after lag \\(q\\) Tails off PACF Cuts off after lag \\(p\\) Tails off Tails off As an example let us consider the following two ARMA(\\(q\\)) models: \\[ \\begin{aligned} X_t &amp;= 0.3 X_{t-1} - 0.8 X_{t-2} + 0.7 W_{t-1} + W_t \\\\ Y_t &amp;= 1.2 X_{t-1} - 0.25 X_{t-2} - 0.1 W_{t-1} - 0.75 W_{t-2} + W_t, \\\\ \\end{aligned} \\] where \\(W_t \\overset{iid}{\\sim} \\mathcal{N}(0, 1)\\) Xt = gen_gts(n = 500, ARMA(ar = c(0.3,-0.8), ma = 0.7, sigma2 = 1)) Yt = gen_gts(n = 500, ARMA(ar = c(1.2, -0.25), ma = c(-0.1, -0.75), sigma2 = 1)) par(mfrow = c(2,1)) plot(Xt, main = expression(&quot;Simulated process: &quot;* X[t] *&quot; with &quot;* T *&quot; = 500&quot;)) plot(Yt, main = expression(&quot;Simulated process: &quot;* Y[t] *&quot; with &quot;* T *&quot; = 500&quot;)) Figure 4.1: TO DO The theoretical ACF/PACF par(mfrow = c(1,2)) plot(theo_acf(ar = c(0.3,-0.8), ma = 0.7), main = expression(&quot;Theo. ACF - MA(1); &quot;* theta *&quot; = 0.9&quot;)) plot(theo_pacf(ar = c(0.3,-0.8), ma = 0.7), main = expression(&quot;Theo. PACF - MA(1); &quot;* theta *&quot; = 0.9&quot;)) Figure 4.2: TO DO par(mfrow = c(1,2)) plot(theo_acf(ar = c(1.2, -0.25), ma = c(-0.1, -0.75)), main = expression(&quot;Theo. ACF - MA(1); &quot;* theta *&quot; = 0.9&quot;)) plot(theo_pacf(ar = c(1.2, -0.25), ma = c(-0.1, -0.75)), main = expression(&quot;Theo. ACF - MA(1); &quot;* theta *&quot; = -0.9&quot;)) Figure 4.3: TO DO Remark on the identification of the order of an ARMA model: ACF and PACF of ARMA models are difficult to interpret. It is generally easier to consider a list of candidate models and selected the ``best’’ model in this list using a model selection criterion or an estimator of the prediction error (e.g. MAPE). Check diagnostic plot to assess if the model is reasonable for this time series. Xt = gts(as.numeric(dmseries(&quot;https://datamarket.com/data/set/22y1/annual-copper-prices-1800-1997#!ds=22y1&amp;display=line&quot;)), start = 1921, freq = 12, name_ts = &quot;Copper prices (minus the long-term trend)&quot;, data_name = &quot;Copper Price&quot;, name_time = &quot;&quot;) plot(Xt) Figure 4.4: TO DO corr_analysis(Xt) Figure 4.5: Empirical ACF (left) and PACF (right) of the Copper time series data. select(ARMA(4,5), Xt) Figure 4.6: Empirical ACF (left) and PACF (right) of the Copper time series data. ## ## Call: ## arima(x = xt, order = c(3, 0, 5), include.mean = include.mean) ## ## Coefficients: ## ar1 ar2 ar3 ma1 ma2 ma3 ma4 ma5 ## -0.4939 0.3748 0.8625 1.4987 0.7951 -0.4955 -0.5172 -0.2575 ## s.e. 0.0531 0.0635 0.0519 0.1301 0.2081 0.1869 0.1638 0.0862 ## intercept ## 0.1406 ## s.e. 0.3949 ## ## sigma^2 estimated as 0.5441: log likelihood = -223.08, aic = 466.15 To decide: evaluate(list(AR(1), ARMA(3,2), ARMA(3, 5)), Xt, criterion = &quot;MAPE&quot;, start = 0.5) model_copper = estimate(ARMA(3,2), Xt) check(model_copper) Figure 4.7: Diagnostic plots for the residuals of a TO DO "],
["arima.html", "5.2 ARIMA", " 5.2 ARIMA "],
["sarima.html", "5.3 SARIMA", " 5.3 SARIMA 5.3.1 Real data example Xt = gts(as.numeric(dmseries(&quot;https://datamarket.com/data/set/22pw/monthly-lake-erie-levels-1921-1970#!ds=22pw&amp;display=line&quot;)), start = 1921, freq = 12, name_ts = &quot;Water Levels&quot;, data_name = &quot;Monthly Lake Erie Levels&quot;, name_time = &quot;&quot;) plot(Xt) Figure 4.8: TO DO corr_analysis(Xt) Figure 4.9: Empirical ACF (left) and PACF (right) of the Lake Erie time series data. Xt = gts(as.numeric(dmseries(&quot;https://datamarket.com/data/set/235j/number-of-daily-births-in-quebec-jan-01-1977-to-dec-31-1990#!ds=235j&amp;display=line&quot;)), start = 1977, freq = 365, name_ts = &quot;Number of Births&quot;, data_name = &quot;Number of Births in Quebec&quot;, name_time = &quot;&quot;) plot(Xt) Figure 4.10: TO DO corr_analysis(Xt, lag.max = 50) Figure 4.11: Empirical ACF (left) and PACF (right) of the Births time series data. mod = estimate(SARIMA(ar = 2, ma = 1, sar = 2, sma = 1, s = 7, si = 1), Xt, method = &quot;mle&quot;) check(mod) predict(mod, n.ahead = 30) "]
]
